{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5ca46314-a8c9-43db-ab68-53508f9afe0d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-------+----+------+-------+-----------+\n|  id|   name| age|salary|country| department|\n+----+-------+----+------+-------+-----------+\n|   1| manish|  26| 20000|  india|         IT|\n|   2|  rahul|null| 40000|germany|engineering|\n|   3|  pawan|  12| 60000|  india|      sales|\n|   4|roshini|  44|  null|     uk|engineering|\n|   5|raushan|  35| 70000|  india|      sales|\n|   6|   null|  29|200000|     uk|         IT|\n|   7|   adam|  37| 65000|     us|         IT|\n|   8|  chris|  16| 40000|     us|      sales|\n|null|   null|null|  null|   null|       null|\n|   7|   adam|  37| 65000|     us|         IT|\n+----+-------+----+------+-------+-----------+\n\n"
     ]
    }
   ],
   "source": [
    "emp_data = [\n",
    "    (1, \"manish\", 26, 20000, \"india\", \"IT\"),\n",
    "    (2, \"rahul\", None, 40000, \"germany\", \"engineering\"),\n",
    "    (3, \"pawan\", 12, 60000, \"india\", \"sales\"),\n",
    "    (4, \"roshini\", 44, None, \"uk\", \"engineering\"),\n",
    "    (5, \"raushan\", 35, 70000, \"india\", \"sales\"),\n",
    "    (6, None, 29, 200000, \"uk\", \"IT\"),\n",
    "    (7, \"adam\", 37, 65000, \"us\", \"IT\"),\n",
    "    (8, \"chris\", 16, 40000, \"us\", \"sales\"),\n",
    "    (None, None, None, None, None, None),\n",
    "    (7, \"adam\", 37, 65000, \"us\", \"IT\"),\n",
    "]\n",
    "schema = [\"id\", \"name\", \"age\", \"salary\", \"country\", \"department\"]\n",
    "df = spark.createDataFrame(data=emp_data, schema=schema)\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4338668e-2407-459b-8fd9-d4e75692e659",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-------+----+------+-------+-----------+--------+\n|  id|   name| age|salary|country| department|is_adult|\n+----+-------+----+------+-------+-----------+--------+\n|   1| manish|  26| 20000|  india|         IT|    true|\n|   2|  rahul|null| 40000|germany|engineering|    null|\n|   3|  pawan|  12| 60000|  india|      sales|   false|\n|   4|roshini|  44|  null|     uk|engineering|    true|\n|   5|raushan|  35| 70000|  india|      sales|    true|\n|   6|   null|  29|200000|     uk|         IT|    true|\n|   7|   adam|  37| 65000|     us|         IT|    true|\n|   8|  chris|  16| 40000|     us|      sales|   false|\n|null|   null|null|  null|   null|       null|    null|\n|   7|   adam|  37| 65000|     us|         IT|    true|\n+----+-------+----+------+-------+-----------+--------+\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, when\n",
    "\n",
    "df.withColumn(\n",
    "    \"is_adult\",\n",
    "    when(col(\"age\") >= 18, True).when(col(\"age\") <= 18, False).otherwise(None),\n",
    ").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "18b8aff3-f194-46c2-a318-a2ed69ee9262",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-------+---+------+-------+-----------+\n|  id|   name|age|salary|country| department|\n+----+-------+---+------+-------+-----------+\n|   1| manish| 26| 20000|  india|         IT|\n|   2|  rahul| -1| 40000|germany|engineering|\n|   3|  pawan| 12| 60000|  india|      sales|\n|   4|roshini| 44|  null|     uk|engineering|\n|   5|raushan| 35| 70000|  india|      sales|\n|   6|   null| 29|200000|     uk|         IT|\n|   7|   adam| 37| 65000|     us|         IT|\n|   8|  chris| 16| 40000|     us|      sales|\n|null|   null| -1|  null|   null|       null|\n|   7|   adam| 37| 65000|     us|         IT|\n+----+-------+---+------+-------+-----------+\n\n"
     ]
    }
   ],
   "source": [
    "# fill something for null values\n",
    "df.withColumn(\"age\", when(col(\"age\").isNull(), -1).otherwise(col(\"age\"))).show()"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "1"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "If,else",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}